# 主要機能と優先順位

## 1. 機能一覧

### コア機能（MVP-Cに含まれる機能）

#### Phase 1: 基盤機能

1. **ベースリサーチ機能**
   - Perplexity API連携
   - 基本的な検索・結果表示
   - 基本UI実装

#### Phase 2: 革新的操作機能

2. **テキスト選択機能**
   - リサーチ結果からのテキスト範囲選択
   - ブラウザ標準の選択表示を使用（独自ハイライトなし）

3. **音声コマンド入力**
   - Web Speech API を使用した音声認識
   - リアルタイム音声→テキスト変換

4. **LLM音声解釈システム**
   - 自然言語での曖昧な発話を構造化された命令に変換
   - 8つのアクションパターンによる意図判定

5. **コンテキスト理解・実行**
   - 選択テキスト + 音声命令 + 文脈を総合分析
   - 最適なリサーチアクションの自動実行

#### Phase 3: 先進的可視化

6. **動的可視化UI**
   - リサーチフローの美しいビジュアライゼーション
   - 情報の関係性を動的に表現
   - インタラクティブな情報マップ

7. **リアルタイム展開表示**
   - AIの思考プロセスのリアルタイム可視化
   - リサーチ進行状況の視覚的フィードバック

## 2. 音声解釈アクションパターン

### 8つの解釈パターン

| パターン               | 発話例                               | アクション内容                             |
| ---------------------- | ------------------------------------ | ------------------------------------------ |
| **深堀り系**           | 「もっと詳しく」「なぜそうなるの？」 | 選択テキストを起点とした詳細検索・原因分析 |
| **視点変更系**         | 「他の観点でも」「反対意見は？」     | 異なる視点・対立意見での再検索             |
| **具体化系**           | 「具体例ある？」「実際どうなの？」   | 事例・実例・ケーススタディの検索           |
| **データ・根拠系**     | 「データある？」「根拠は？」         | 統計情報・調査結果・定量データの検索       |
| **比較・関連系**       | 「他と比べると？」「関連する話は？」 | 競合比較・類似事例・関連トピックの検索     |
| **時系列・トレンド系** | 「今後どうなる？」「トレンドは？」   | 将来予測・歴史的変遷・トレンド分析         |
| **実用・応用系**       | 「どう使えるの？」「メリットは？」   | 実用例・活用方法・pros/cons分析            |
| **要約・整理系**       | 「まとめて」「ポイントは？」         | 要点整理・構造化・サマリ生成               |

### LLM解釈フロー

```
ユーザー発話 → LLM解析 → 意図判定 → アクション選択 → 実行
              ↓           ↓           ↓           ↓
            自然言語    8パターン    具体的命令   API実行
```

## 3. 実装優先順位

### MVP-C（完全体験版）の開発順序

#### Sprint 1: 基盤構築（2-3週間）

- [ ] Perplexity API 連携実装
- [ ] 基本UI/UX設計・実装
- [ ] テキスト選択機能

#### Sprint 2: 音声・解釈システム（3-4週間）

- [ ] Web Speech API 統合
- [ ] LLM音声解釈システム実装
- [ ] 8パターンのアクション実装
- [ ] コンテキスト理解ロジック

#### Sprint 3: 可視化システム（3-4週間）

- [ ] 動的可視化コンポーネント設計
- [ ] リサーチフロー可視化実装
- [ ] インタラクティブUI実装
- [ ] リアルタイム表示機能

#### Sprint 4: 統合・最適化（1-2週間）

- [ ] 全機能の統合テスト
- [ ] パフォーマンス最適化
- [ ] UX調整・ポリッシュ

## 4. 将来機能（Phase 4以降）

### 自動化・学習機能

1. **ユーザー行動学習**
   - ユーザーの選択パターン学習
   - パーソナライズされたリサーチ提案

2. **完全自動化**
   - 音声コマンドなしでの自動深堀り
   - ユーザーの意図先読み機能

3. **マルチエージェント協調**
   - 複数AI エージェントでの並列リサーチ
   - 異なる専門性を持つエージェントの協働

### 高度な可視化

4. **3D可視化**
   - 3次元での情報関係性表現
   - VR/AR対応の可能性

5. **協働機能**
   - チーム内でのリサーチ共有
   - リアルタイム共同リサーチ

## 5. 技術スタック（想定）

### フロントエンド

- React/Next.js または Vue.js/Nuxt.js
- TypeScript
- D3.js または Three.js (可視化)
- Web Speech API

### バックエンド

- Node.js/Express または Python/FastAPI
- Perplexity API
- OpenAI API/Claude API (音声解釈用)

### インフラ

- Vercel/Netlify (フロントエンド)
- Railway/Render (バックエンド)

## 6. 成功指標

### 定量指標

- **操作回数削減**: 従来比1/3以下のアクション数
- **リサーチ時間短縮**: 同等成果を1/2以下の時間で達成
- **音声解釈精度**: 95%以上の意図認識精度

### 定性指標

- **「未来的」体験**: ユーザーテスト時の驚きの声
- **直感性**: 説明なしでの操作成功率90%以上
- **継続利用意向**: 体験後のリピート意向80%以上

---

_この機能設計は、AI時代の新しいリサーチ体験を実現するための革新的なインタラクションパターンを定義しています。_
