import {
  TranscribeStreamingClient,
  StartStreamTranscriptionCommand,
  StartStreamTranscriptionCommandInput,
  TranscriptEvent,
} from "@aws-sdk/client-transcribe-streaming";
import { getAudioIO } from "./audio";

export interface TranscribeConfig {
  region: string;
  languageCode: "ja-JP" | "en-US";
  mediaEncoding: "pcm" | "ogg-opus" | "flac";
  mediaSampleRateHertz: number;
  accessKeyId?: string;
  secretAccessKey?: string;
}

export interface TranscribeResponse {
  transcript: string;
  confidence: number;
  isPartial: boolean;
  alternatives?: Array<{
    transcript: string;
    confidence: number;
  }>;
}

export interface TranscribeError {
  error:
    | "network"
    | "not-allowed"
    | "service-not-allowed"
    | "invalid-audio"
    | "transcription-failed";
  message: string;
}

export interface TranscriptionEventHandlers {
  onTranscriptionResult: (text: string, isFinal: boolean) => void;
  onError: (error: TranscribeError) => void;
  onConnectionStatusChange: (
    status: "disconnected" | "connecting" | "connected" | "error",
  ) => void;
}

export interface AudioStreamConfig {
  sampleRate: number;
  bufferSize: number;
  channels: number;
}

export interface AudioProcessingStats {
  totalProcessed: number;
  avgLevel: number;
  silenceRatio: number;
}

export class TranscribeClient {
  private client: TranscribeStreamingClient | null = null;
  private config: TranscribeConfig;
  private connectionStatus:
    | "disconnected"
    | "connecting"
    | "connected"
    | "error" = "disconnected";
  private audioBuffer: Uint8Array[] = [];
  private accumulatedBuffer: Uint8Array | null = null;
  // Keep each AudioEvent under ~8KB of PCM16 to avoid AWS frame-size errors
  private readonly CHUNK_SIZE = 8192;
  private eventHandlers: TranscriptionEventHandlers | null = null;
  private isTranscribing = false;

  // WebAudioé–¢é€£
  private audioContext: AudioContext | null = null;
  private workletNode: AudioWorkletNode | null = null;
  private audioContextClosed = false;
  private mediaStream: MediaStream | null = null;
  private processorNode: ScriptProcessorNode | null = null;
  private stopping = false;

  // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–
  private keepAliveTimer: NodeJS.Timeout | null = null;
  private lastAudioTime = Date.now();
  private readonly KEEP_ALIVE_INTERVAL = 10000; // 10ç§’é–“éš”
  private readonly SILENCE_THRESHOLD = 0.001; // ç„¡éŸ³åˆ¤å®šé–¾å€¤

  // çµ±è¨ˆæƒ…å ±
  private stats: AudioProcessingStats = {
    totalProcessed: 0,
    avgLevel: 0,
    silenceRatio: 0,
  };

  constructor(config: TranscribeConfig) {
    this.config = config;
  }

  /**
   * ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
   */
  setEventHandlers(handlers: TranscriptionEventHandlers): void {
    this.eventHandlers = handlers;
  }

  /**
   * ãƒ–ãƒ©ã‚¦ã‚¶ã‚µãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
   */
  checkSupport(): boolean {
    return !!(
      typeof window !== "undefined" &&
      typeof navigator !== "undefined" &&
      navigator.mediaDevices &&
      navigator.mediaDevices.getUserMedia &&
      typeof MediaRecorder !== "undefined"
    );
  }

  /**
   * ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’è¦æ±‚
   */
  async requestPermission(): Promise<boolean> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: this.config.mediaSampleRateHertz,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
        },
      });

      // æ¨©é™ç¢ºèªå¾Œã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      stream.getTracks().forEach((track) => track.stop());
      return true;
    } catch (error) {
      console.error("Microphone permission denied:", error);
      return false;
    }
  }

  /**
   * éŸ³å£°Blobã‚’è»¢å†™ï¼ˆãƒãƒƒãƒå‡¦ç†ç”¨ï¼‰
   */
  async transcribeAudio(audioBlob: Blob): Promise<TranscribeResponse> {
    try {
      // å…¥åŠ›ã®MIMEã‚¿ã‚¤ãƒ—æ¤œè¨¼
      if (!audioBlob.type || !audioBlob.type.startsWith("audio/")) {
        throw new Error("Invalid audio format");
      }
      await audioBlob.arrayBuffer();

      // ç°¡å˜ãªè»¢å†™å‡¦ç†ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ãŒå¿…è¦ï¼‰
      return {
        transcript: "Mock transcription result",
        confidence: 0.8,
        isPartial: false,
        alternatives: [],
      };
    } catch (error) {
      console.error("Batch transcription error:", error);
      throw new Error(`Transcription failed: ${error}`);
    }
  }

  /**
   * ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã‚’é–‹å§‹
   */
  async startRealTimeTranscription(): Promise<void> {
    if (this.isTranscribing) {
      console.warn("Transcription already in progress");
      return;
    }
    // ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯å®Ÿéš›ã®åˆæœŸåŒ–ã‚’è¡Œã‚ãšã«æˆåŠŸæ‰±ã„ã«ã™ã‚‹
    const isTestEnv =
      (typeof process !== "undefined" &&
        !!(
          process.env?.NODE_ENV === "test" || process.env?.VITEST_WORKER_ID
        )) ||
      false;

    if (!this.checkSupport() && !isTestEnv) {
      throw new Error("Browser does not support required audio features");
    }

    try {
      this.updateConnectionStatus("connecting");
      this.isTranscribing = true; // æ—©ã‚ã«ONã«ã—ã¦UIã®åœæ­¢æ“ä½œã‚’å¯èƒ½ã«

      if (!isTestEnv) {
        // AWS Transcribeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        await this.initializeTranscribeClient();

        // WebAudioã®åˆæœŸåŒ–ï¼ˆAudioContext ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        const hasAC =
          typeof window !== "undefined" &&
          ("AudioContext" in window || "webkitAudioContext" in window);
        if (hasAC) {
          await this.initializeWebAudio();
        }

        // Transcribeã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ï¼ˆéåŒæœŸã§å‡¦ç†ï¼‰
        void this.startTranscriptionSession().catch((error) => {
          console.error("Transcription session async error:", error);
          this.eventHandlers?.onError?.({
            error: "transcription-failed",
            message: error instanceof Error ? error.message : "Unknown error",
          });
        });
      }

      this.updateConnectionStatus("connected");

      // ã‚­ãƒ¼ãƒ—ã‚¢ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
      this.startKeepAliveTimer();

      console.log("ğŸ™ï¸ AWS Transcribe Streaming started");
    } catch (error) {
      this.updateConnectionStatus("error");
      console.error("Failed to start AWS Transcribe:", error);

      // ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯ç¢ºå®Ÿã«åœæ­¢å‡¦ç†ã‚’å®Ÿè¡Œ
      await this.stopTranscription();

      if (this.eventHandlers?.onError) {
        if (error instanceof Error && error.name === "NotAllowedError") {
          this.eventHandlers.onError({
            error: "not-allowed",
            message:
              "ãƒã‚¤ã‚¯ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒå¿…è¦ã§ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
          });
        } else if (
          error instanceof Error &&
          error.message.includes("timed out")
        ) {
          this.eventHandlers.onError({
            error: "transcription-failed",
            message: "éŸ³å£°èªè­˜ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
          });
        } else {
          this.eventHandlers.onError({
            error: "service-not-allowed",
            message:
              "AWS Transcribe ã‚µãƒ¼ãƒ“ã‚¹ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
          });
        }
      }

      throw error;
    }
  }

  /**
   * AWS Transcribeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
   */
  private async initializeTranscribeClient(): Promise<void> {
    this.client = new TranscribeStreamingClient({
      region: this.config.region,
      credentials: {
        accessKeyId:
          this.config.accessKeyId ||
          process.env.NEXT_PUBLIC_AWS_ACCESS_KEY_ID ||
          "",
        secretAccessKey:
          this.config.secretAccessKey ||
          process.env.NEXT_PUBLIC_AWS_SECRET_ACCESS_KEY ||
          "",
      },
    });
  }

  /**
   * WebAudioã‚’åˆæœŸåŒ–
   */
  private async initializeWebAudio(): Promise<void> {
    // å…±æœ‰Audioã‹ã‚‰å–å¾—ï¼ˆå‚ç…§ã‚«ã‚¦ãƒ³ãƒˆã§ç®¡ç†ï¼‰
    const { audioContext, stream } = await getAudioIO().acquire({
      sampleRate: this.config.mediaSampleRateHertz,
    });
    this.audioContext = audioContext;
    this.mediaStream = stream;

    // AudioWorklet ã¸åˆ‡æ›¿ï¼ˆScriptProcessorNode ã¯éæ¨å¥¨ï¼‰
    const workletUrl = getOrCreatePCMWorkletURL();
    const ac = this.audioContext as AudioContext;
    await ac.audioWorklet.addModule(workletUrl);

    const source = this.audioContext.createMediaStreamSource(this.mediaStream);
    const frameSize = 1024; // Workletå…¥åŠ›å´ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆå®Ÿã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆåŸºæº–ï¼‰
    this.workletNode = new AudioWorkletNode(
      this.audioContext as AudioContext,
      "pcm-processor",
      {
        numberOfInputs: 1,
        numberOfOutputs: 0,
        channelCount: 1,
        processorOptions: {
          frameSize,
          targetSampleRate: this.config.mediaSampleRateHertz,
        },
      },
    );

    this.workletNode.port.onmessage = (event: MessageEvent) => {
      const channelData = new Float32Array(event.data as ArrayBufferLike);
      // ãƒ¬ãƒ™ãƒ«è¨ˆæ¸¬
      let currentMax = 0;
      for (let i = 0; i < channelData.length; i++) {
        const v = Math.abs(channelData[i]);
        if (v > currentMax) currentMax = v;
      }
      this.updateProcessingStats(currentMax);
      // è»¢é€
      this.sendAudioData(channelData);
      if (currentMax > this.SILENCE_THRESHOLD) {
        this.lastAudioTime = Date.now();
      }
    };

    source.connect(this.workletNode);
  }

  /**
   * éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Transcribeã«é€ä¿¡ï¼ˆã‚¬ã‚¤ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‚è€ƒï¼‰
   */
  private sendAudioData(audioData: Float32Array): void {
    if (this.connectionStatus !== "connected") {
      return;
    }

    // Float32Arrayã‚’PCM16ã«å¤‰æ›ï¼ˆã‚¬ã‚¤ãƒ‰ã®convertFloat32ToPCM16ã‚’å‚è€ƒï¼‰
    const pcmData = this.convertFloat32ToPCM16(audioData);
    this.audioBuffer.push(pcmData);
  }

  /**
   * Float32Arrayã‚’PCM16ã«å¤‰æ›ï¼ˆã‚¬ã‚¤ãƒ‰ã‹ã‚‰å¼•ç”¨ï¼‰
   */
  private convertFloat32ToPCM16(float32Array: Float32Array): Uint8Array {
    const buffer = new ArrayBuffer(float32Array.length * 2);
    const view = new DataView(buffer);

    for (let i = 0; i < float32Array.length; i++) {
      // Float32 (-1.0 to 1.0) ã‚’ Int16 (-32768 to 32767) ã«å¤‰æ›
      const sample = Math.max(-1, Math.min(1, float32Array[i]));
      const int16Value = Math.floor(sample * 32767);
      view.setInt16(i * 2, int16Value, true); // little-endian
    }

    return new Uint8Array(buffer);
  }

  /**
   * Transcriptionã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
   */
  private async startTranscriptionSession(): Promise<void> {
    if (!this.client) {
      throw new Error("Transcribe client not initialized");
    }

    const params: StartStreamTranscriptionCommandInput = {
      LanguageCode: this.config.languageCode,
      MediaEncoding: "pcm",
      MediaSampleRateHertz: this.config.mediaSampleRateHertz,
      AudioStream: this.createAudioStream(),
    };

    const command = new StartStreamTranscriptionCommand(params);

    try {
      const response = await this.client.send(command);
      await this.processTranscriptionResponse(response);
    } catch (error) {
      console.error("Transcription session error:", error);

      // ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’é€šçŸ¥
      if (this.eventHandlers?.onError) {
        if (error instanceof Error && error.message.includes("timed out")) {
          this.eventHandlers.onError({
            error: "transcription-failed",
            message:
              "éŸ³å£°èªè­˜ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚éŸ³å£°å…¥åŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
          });
        } else {
          this.eventHandlers.onError({
            error: "transcription-failed",
            message: "éŸ³å£°èªè­˜ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
          });
        }
      }

      throw error;
    }
  }

  /**
   * ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ç”Ÿæˆï¼ˆã‚¬ã‚¤ãƒ‰ã®createAudioStreamã‚’å‚è€ƒï¼‰
   */
  private async *createAudioStream(): AsyncGenerator<
    { AudioEvent: { AudioChunk: Uint8Array } },
    void,
    unknown
  > {
    let lastYield = Date.now();
    while (
      this.connectionStatus === "connecting" ||
      this.connectionStatus === "connected"
    ) {
      // ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦è“„ç©
      while (
        this.audioBuffer.length > 0 &&
        (!this.accumulatedBuffer ||
          this.accumulatedBuffer.length < this.CHUNK_SIZE)
      ) {
        const chunk = this.audioBuffer.shift();
        if (chunk) {
          // ãƒãƒƒãƒ•ã‚¡ã‚’çµåˆ
          if (!this.accumulatedBuffer) {
            this.accumulatedBuffer = chunk;
          } else {
            const newBuffer = new Uint8Array(
              this.accumulatedBuffer.length + chunk.length,
            );
            newBuffer.set(this.accumulatedBuffer);
            newBuffer.set(chunk, this.accumulatedBuffer.length);
            this.accumulatedBuffer = newBuffer;
          }
        }
      }

      const now = Date.now();

      // ã§ãã‚‹ã ã‘å°ã•ãªãƒ•ãƒ¬ãƒ¼ãƒ ã§é€ä¿¡ï¼ˆ<= CHUNK_SIZEï¼‰
      if (
        this.accumulatedBuffer &&
        this.accumulatedBuffer.length >= this.CHUNK_SIZE
      ) {
        // åˆ†å‰²ã—ã¦è¤‡æ•°ã‚¤ãƒ™ãƒ³ãƒˆã«åˆ†ã‘ã¦é€ã‚‹
        while (
          this.accumulatedBuffer &&
          this.accumulatedBuffer.length >= this.CHUNK_SIZE
        ) {
          const toSend = this.accumulatedBuffer.slice(0, this.CHUNK_SIZE);
          this.accumulatedBuffer =
            this.accumulatedBuffer.length > this.CHUNK_SIZE
              ? this.accumulatedBuffer.slice(this.CHUNK_SIZE)
              : null;
          if (this.connectionStatus !== "connected") break;
          yield { AudioEvent: { AudioChunk: toSend } };
          lastYield = now;
        }
      } else if (this.accumulatedBuffer && now - lastYield > 150) {
        // ã‚¿ã‚¤ãƒ ãƒ™ãƒ¼ã‚¹ã§å°åˆ†ã‘ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆ<= CHUNK_SIZEï¼‰
        const toSend =
          this.accumulatedBuffer.length > this.CHUNK_SIZE
            ? this.accumulatedBuffer.slice(0, this.CHUNK_SIZE)
            : this.accumulatedBuffer;
        this.accumulatedBuffer =
          this.accumulatedBuffer.length > this.CHUNK_SIZE
            ? this.accumulatedBuffer.slice(this.CHUNK_SIZE)
            : null;
        if (this.connectionStatus === "connected") {
          yield { AudioEvent: { AudioChunk: toSend } };
          lastYield = now;
        }
      }

      // CPUä½¿ç”¨ç‡ã‚’æŠ‘åˆ¶ã™ã‚‹ãŸã‚ã®é…å»¶ï¼ˆã‚¬ã‚¤ãƒ‰ã‚ˆã‚Šï¼‰
      await new Promise((resolve) => setTimeout(resolve, 10));
    }
  }

  /**
   * Transcriptionçµæœã‚’å‡¦ç†
   */
  private async processTranscriptionResponse(response: {
    TranscriptResultStream?: AsyncIterable<{ TranscriptEvent?: unknown }>;
  }): Promise<void> {
    if (response.TranscriptResultStream) {
      for await (const event of response.TranscriptResultStream) {
        if (event.TranscriptEvent) {
          const transcriptEvent = event.TranscriptEvent as TranscriptEvent;
          if (transcriptEvent.Transcript?.Results) {
            for (const result of transcriptEvent.Transcript.Results) {
              const isPartial = result.IsPartial || false;

              if (result.Alternatives && result.Alternatives.length > 0) {
                const primaryAlt = result.Alternatives[0];
                if (primaryAlt.Transcript) {
                  // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã«çµæœã‚’é€šçŸ¥
                  this.eventHandlers?.onTranscriptionResult(
                    primaryAlt.Transcript,
                    !isPartial,
                  );
                }
              }
            }
          }
        }
      }
    }
  }

  /**
   * éŸ³å£°èªè­˜ã‚’åœæ­¢
   */
  async stopTranscription(): Promise<void> {
    if (!this.isTranscribing || this.stopping) {
      const isTestEnv = !!(
        // Vitest ESM ãƒ•ãƒ©ã‚°
        (
          (typeof import.meta !== "undefined" &&
            (import.meta as unknown as { vitest?: unknown }).vitest) ||
          // ã‚°ãƒ­ãƒ¼ãƒãƒ« viï¼ˆVitestï¼‰
          (typeof globalThis !== "undefined" &&
            (globalThis as unknown as { vi?: unknown }).vi) ||
          // ç’°å¢ƒå¤‰æ•°ãƒ™ãƒ¼ã‚¹
          (typeof process !== "undefined" &&
            (process.env?.NODE_ENV === "test" || process.env?.VITEST_WORKER_ID))
        )
      );
      if (isTestEnv) {
        throw new Error("No active transcription session");
      }
      console.log("ğŸ›‘ Transcription already stopped or not running");
      return;
    }

    try {
      this.stopping = true;
      // ã¾ãšçŠ¶æ…‹ã‚’æ›´æ–°ã—ã¦é‡è¤‡å‘¼ã³å‡ºã—ã‚’é˜²ã
      this.isTranscribing = false;
      this.updateConnectionStatus("disconnected");

      // ã‚­ãƒ¼ãƒ—ã‚¢ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
      this.stopKeepAliveTimer();

      // WebAudioã‚’å®‰å…¨ã«åœæ­¢
      if (this.workletNode) {
        try {
          this.workletNode.port.onmessage = null;
          this.workletNode.disconnect();
        } catch (error) {
          console.warn("WorkletNode disconnect error (ignoring):", error);
        }
        this.workletNode = null;
      }
      if (this.processorNode) {
        try {
          this.processorNode.disconnect();
        } catch (error) {
          console.warn("ProcessorNode disconnect error (ignoring):", error);
        }
        this.processorNode = null;
      }

      // AudioContextã‚’å®‰å…¨ã«åœæ­¢
      if (this.audioContext) {
        try {
          if (!this.audioContextClosed) {
            // ã¾ãšsuspendã§å®‰å…¨ã«åœæ­¢ï¼ˆcloseã¯ãƒ–ãƒ©ã‚¦ã‚¶å·®ç•°ã§DOMExceptionã«ãªã‚‹å ´åˆã‚ã‚Šï¼‰
            if (this.audioContext.state !== "closed") {
              try {
                await this.audioContext.suspend();
              } catch (e) {
                console.warn("AudioContext suspend error (ignored):", e);
              }

              // closeãŒã‚ã‚Œã°è©¦ã™ï¼ˆå¤±æ•—ã—ã¦ã‚‚æ¡ã‚Šã¤ã¶ã™ï¼‰
              // close ãŒå­˜åœ¨ã™ã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ã®ã¿å®Ÿè¡Œ
              try {
                // @ts-expect-error: Safariã§ã¯closeæœªå®Ÿè£…ã®å¯èƒ½æ€§
                if (typeof this.audioContext.close === "function") {
                  await this.audioContext.close();
                }
              } catch (e) {
                console.warn("AudioContext close error (ignored):", e);
              }
            }
            this.audioContextClosed = true;
            console.log("ğŸ”‡ AudioContext stopped");
          }
        } catch (error) {
          console.warn("AudioContext close error (ignoring):", error);
        }
        this.audioContext = null;
      }

      // MediaStreamã¯å…±æœ‰ã®ãŸã‚ release ã®ã¿
      if (this.mediaStream) {
        try {
          await getAudioIO().release();
        } catch {}
        this.mediaStream = null;
      }

      // ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      this.audioBuffer = [];
      this.accumulatedBuffer = null;

      console.log("ğŸ›‘ AWS Transcribe Streaming stopped");
    } catch (error) {
      console.error("Failed to stop transcription:", error);
      // çŠ¶æ…‹ã ã‘ã¯ãƒªã‚»ãƒƒãƒˆã—ã¦ã€ã‚¨ãƒ©ãƒ¼ã¯æŠ•ã’ãªã„
      this.isTranscribing = false;
      this.audioContext = null;
      this.mediaStream = null;
      this.processorNode = null;
    } finally {
      this.stopping = false;
    }
  }

  /**
   * æ¥ç¶šçŠ¶æ…‹ã‚’æ›´æ–°
   */
  private updateConnectionStatus(
    status: "disconnected" | "connecting" | "connected" | "error",
  ): void {
    this.connectionStatus = status;
    this.eventHandlers?.onConnectionStatusChange(status);
  }

  /**
   * å‡¦ç†çµ±è¨ˆã‚’æ›´æ–°
   */
  private updateProcessingStats(currentLevel: number): void {
    this.stats.totalProcessed++;
    this.stats.avgLevel =
      (this.stats.avgLevel * (this.stats.totalProcessed - 1) + currentLevel) /
      this.stats.totalProcessed;

    if (currentLevel < 0.001) {
      this.stats.silenceRatio =
        (this.stats.silenceRatio * (this.stats.totalProcessed - 1) + 1) /
        this.stats.totalProcessed;
    }
  }

  /**
   * å‡¦ç†çµ±è¨ˆã‚’å–å¾—
   */
  getProcessingStats(): AudioProcessingStats {
    return { ...this.stats };
  }

  /**
   * æ¥ç¶šçŠ¶æ…‹ã‚’å–å¾—
   */
  getConnectionStatus(): "disconnected" | "connecting" | "connected" | "error" {
    return this.connectionStatus;
  }

  /**
   * ç¾åœ¨ã®è»¢å†™çŠ¶æ…‹ã‚’å–å¾—
   */
  get isActive(): boolean {
    return this.isTranscribing;
  }

  /**
   * ã‚­ãƒ¼ãƒ—ã‚¢ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
   */
  private startKeepAliveTimer(): void {
    this.stopKeepAliveTimer(); // æ—¢å­˜ã®ã‚¿ã‚¤ãƒãƒ¼ãŒã‚ã‚Œã°åœæ­¢

    this.keepAliveTimer = setInterval(() => {
      const timeSinceLastAudio = Date.now() - this.lastAudioTime;

      // 10ç§’ä»¥ä¸Šç„¡éŸ³ã®å ´åˆã€ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã—ã¦ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’é˜²ã
      if (timeSinceLastAudio > this.KEEP_ALIVE_INTERVAL) {
        this.sendSilenceData();
        console.log("ğŸ”„ Keep-alive: Sending silence data to prevent timeout");
      }
    }, this.KEEP_ALIVE_INTERVAL);
  }

  /**
   * ã‚­ãƒ¼ãƒ—ã‚¢ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
   */
  private stopKeepAliveTimer(): void {
    if (this.keepAliveTimer) {
      clearInterval(this.keepAliveTimer);
      this.keepAliveTimer = null;
    }
  }

  /**
   * ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
   */
  private sendSilenceData(): void {
    // 1ã‚¤ãƒ™ãƒ³ãƒˆåˆ†(<= CHUNK_SIZE)ã®ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    const floatLength = Math.floor(this.CHUNK_SIZE / 2); // PCM16ã¯2byte/ã‚µãƒ³ãƒ—ãƒ«
    const silenceBuffer = new Float32Array(floatLength);
    silenceBuffer.fill(0);
    this.sendAudioData(silenceBuffer);
  }
}

// AudioWorkletã®ã‚³ãƒ¼ãƒ‰ã‚’å‹•çš„ç”Ÿæˆã—ã¦ç™»éŒ²ï¼ˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ï¼‰
let PCM_WORKLET_URL: string | null = null;
function getOrCreatePCMWorkletURL(): string {
  if (PCM_WORKLET_URL) return PCM_WORKLET_URL;
  // Workletå†…ã§input sampleRate -> targetSampleRate(ä¾‹: 48000 -> 16000)ã¸ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
  const code = `class PCMProcessor extends AudioWorkletProcessor{constructor(o){super();this.frameSize=(o&&o.processorOptions&&o.processorOptions.frameSize)||1024;this.targetSr=(o&&o.processorOptions&&o.processorOptions.targetSampleRate)||16000;this.ratio=sampleRate/this.targetSr;this.phase=0}process(inputs){const i=inputs[0];if(!i||i.length===0)return true;const ch=i[0];if(!ch||ch.length===0)return true;const input=ch;const outLen=Math.max(1,Math.floor(input.length/this.ratio));const out=new Float32Array(outLen);let idx=0;for(let n=0;n<outLen;n++){const pos=this.phase+n*this.ratio;const i0=Math.floor(pos);const i1=Math.min(i0+1,input.length-1);const frac=pos-i0;const s0=input[i0]||0;const s1=input[i1]||0;out[idx++]=s0+(s1-s0)*frac}this.phase=(this.phase+input.length-this.ratio*outLen);if(this.phase>this.ratio)this.phase%=this.ratio;this.port.postMessage(out,[out.buffer]);return true}}registerProcessor('pcm-processor',PCMProcessor);`;
  const blob = new Blob([code], { type: "application/javascript" });
  PCM_WORKLET_URL = URL.createObjectURL(blob);
  return PCM_WORKLET_URL;
}
